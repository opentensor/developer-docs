{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid Alpha (Consensus based weights)\n",
    "\n",
    "This notebook accompanies the release of the consensus-based weight feature. The weight we are referring to here is the alpha term in the moving average portion of the bond calculation. See the medium post for a detailed discussion of the reasoning behind this update.\n",
    "\n",
    "Here, we propose another approach in addition to the commitment scheme to amplify the advantage of validators that take actions earlier. In turn, this amplifies the disadvantage of validators who copy or act reactively to other validators' actions. Once this disadvantage reaches a certain threshold, it becomes preferable for TAO owners to either perform miner-evaluation work as intended or delegate their stakes to other validators who perform such work.\n",
    "\n",
    "\n",
    "The rest of this notebook shows a method subnet owners can use to determine their preferred value of alpha low.\n",
    "\n",
    "Briefly, you enter your subnet of choice and pick several values of alpha low you wish to evaluate.\n",
    "\n",
    "The notebook will download a number of metagraphs and recompute the dividend using the new formula for alpha. It also assumes that commit-reveal is active so it will include several intervals of delay. The output will show the new dividend relative to the old dividend, any values less than 1 means weight-copiers would have earned less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import bittensor as bt\n",
    "\n",
    "from experiment_setup import ExperimentSetup\n",
    "\n",
    "setup = ExperimentSetup(\n",
    "    liquid_alpha = True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download metagraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_metagraphs import DownloadMetagraph\n",
    "DownloadMetagraph(setup = setup).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_copy_simulation import WeightCopySimulation\n",
    "WeightCopySimulation(setup = setup).run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "(1) Calculate relative dividend rate for weight copier\n",
    "\n",
    "(2) Choose the optimal setting that gives weight copier the most discound in dividend \n",
    "\n",
    "(3) Check how would this setting affect the dividend of regular honest vlaidators \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Calculate relative dividend rate for weight copier under different setting\n",
    "\n",
    "With $D$ as dividend; $S$ as stake; $\\mathcal Z$ as the set of validators.\n",
    "We use the relative dividend rate of the copier $j$,\n",
    "\n",
    "$$G^j = \\frac{D^j/S^j}{\\underset{i \\in \\mathcal Z \\setminus \\{j\\}}{\\mathrm{median}} \\{D^i/S^i\\}}$$\n",
    "\n",
    "- The lower the dividend rate (G), the more discount in dividend we are giving to the weight copier\n",
    "\n",
    "- 360 * conceal_period = commit_reveal_weight_interval\n",
    "\n",
    "- commit_reveal_weight_interval, alpha_low and alpha_high are the parameters made availble for the SN owner to set to the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_dividend_rate(setup):\n",
    "    div_rates = []\n",
    "\n",
    "    for netuid in setup.netuids:\n",
    "        for conceal_period in setup.conceal_periods:\n",
    "            for alpha_low in setup.alpha_lows:\n",
    "                for alpha_high in setup.alpha_highs:\n",
    "                    if alpha_low > alpha_high:\n",
    "                        continue\n",
    "                    \n",
    "                    try: \n",
    "                        with open(f\"{setup.result_path}/yuma_result_netuid{netuid}_conceal{conceal_period}_al{alpha_low:.1f}_ah{alpha_high:.1f}.pkl\", 'rb') as handle:\n",
    "                            _yuma_results = pickle.load(handle)\n",
    "\n",
    "                        dividend = [\n",
    "                            (s[\"validator_reward_normalized\"] / s[\"stake\"]).tolist()\n",
    "                            for idx, s in _yuma_results.items()\n",
    "                        ]\n",
    "\n",
    "                        dividend_df = pd.DataFrame(\n",
    "                            dividend,\n",
    "                            columns=[f\"v{i}\" for i in range(len(dividend[0]) - 1 )] + [\"v_bad\"],\n",
    "                        )\n",
    "                        \n",
    "                        div_last = dividend_df.iloc[-1]\n",
    "                        if (div_last.isna()).any():\n",
    "                            div_rate = None\n",
    "                        else:\n",
    "                            div_rate = div_last[-1] / div_last[:-1].median() \n",
    "\n",
    "                        div_rates.append([netuid, conceal_period, alpha_low, alpha_high, div_rate, div_last])\n",
    "                    \n",
    "                    except:\n",
    "                        div_rates.append([netuid, conceal_period, alpha_low, alpha_high, None, None])\n",
    "\n",
    "\n",
    "    div_rates = pd.DataFrame(div_rates, dtype='float64', columns = ['netuid', 'conceal_period', 'alpha_low', 'alpha_high', 'G', 'dividend'])\n",
    "    div_rates.index = div_rates.index.map(lambda x : x)\n",
    "\n",
    "    return div_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_rates = get_relative_dividend_rate(setup)\n",
    "div_rates.sort_values('G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Choose the optimal setting that gives weight copier the most discound in dividend\n",
    "\n",
    "- The lower the relative dividend rate (G), the more discount in dividend we are giving to the weight copier\n",
    "\n",
    "\n",
    "- commit_reveal_weight_interval = 360 * conceal_period\n",
    "\n",
    "\n",
    "- For the conceal period to be effective, you should set a conceal period large enough to produce enough lost in dividend for the weight copier.\n",
    "\n",
    "| Dividend gain (G) | Effect                                                                                                     |\n",
    "|------------------|------------------------------------------------------------------------------------------------------------|\n",
    "| < 1               | Norminator lost the incentive to delegate to weight copier, weight copier earn less validator take.  |\n",
    "| < 0.82          | Weigh copier lost the incentive to copy weight.                                                      |\n",
    "\n",
    "- If given a conceal period long enough (>15 hours) and the SN still fail to produce enough lost in dividend, it means that there is not enough churn and weight movement in the SN, so the existing weight copiy fix may not work for your SN. Depending on the situation, you may choose to increase competitiveness/ churn in your SN or just leave the weight copier as is. Cause when there is no churn in the SN, there would be no movement in consensus as well, so the weight copier would not be as beneficial. \n",
    "\n",
    "- Note that when the conceal period was set too long, it would slow down the discovery of new miners, putting them at risk for deregistration. Further more, it would means that any change in the network would only be observable after 360 * conceal_period blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_rates['best_param'] = False\n",
    "\n",
    "for netuid in setup.netuids:\n",
    "    df = div_rates[div_rates.netuid == netuid]\n",
    "    df = df[df.G == df.G.min()] # that gives the lowest G \n",
    "    df = df[df.conceal_period == df.conceal_period.min()] # that minimize conceal period\n",
    "    df = df[df.alpha_high == df.alpha_high.max()] # that maximize alpha_high\n",
    "    df = df[df.alpha_low == df.alpha_low.max()] # that maximize alpha_low\n",
    "    div_rates.loc[df.index, 'best_param'] = True\n",
    "\n",
    "best_params = div_rates[div_rates.best_param == True]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Check ther performance with the selected parameter and how would the setting affects the dividend of honest vlaidators  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where would weight copier be positioned compared to honest validator in terms of dividend\n",
    "- The lower the quentile the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in best_params.iterrows(): \n",
    "    div = torch.tensor(list(row.dividend.values))\n",
    "    quantile = (div < div[-1]).sum()/len(div)\n",
    "    best_params.loc[idx, 'quantile'] = quantile.item()\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would the dividend of honest validator change with or without liquid alpha\n",
    "\n",
    "- The goal here is to make sure any parameter we are choosing here would not decrease the dividend that honest peers are receiving. \n",
    "\n",
    "- Note that when alpha_low = alpha_high = 0.9, it is equivalent to when liquid alpha is disabled\n",
    "\n",
    "- We can consider a success when the MSE is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "best_params['MSE'] = None\n",
    "for idx, row in best_params.iterrows(): \n",
    "    original_div = div_rates[(div_rates.netuid == row.netuid) & (div_rates.conceal_period == row.conceal_period) & (div_rates.alpha_high == 0.9) & (div_rates.alpha_low == 0.9)]\n",
    "    original_div = torch.tensor(list(original_div.dividend.values))[0]\n",
    "    la_div = torch.tensor(list(row.dividend.values))\n",
    "    best_params.loc[idx, 'MSE'] = loss(original_div, la_div).item()\n",
    "\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
